{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd464f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('/scratch/oem214/vanilla-rtrl/')\n",
    "from cluster import write_job_file, submit_job\n",
    "from continual_learning import *\n",
    "from core import *\n",
    "from dynamics import *\n",
    "from functions import *\n",
    "from gen_data import *\n",
    "from learning_algorithms import *\n",
    "from optimizers import *\n",
    "from plotting import *\n",
    "from wrappers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f5b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SET UP ALL CONFIGS --- ###\n",
    "from itertools import product\n",
    "n_seeds = 10\n",
    "macro_configs = config_generator(lr=[0.01, 0.001],\n",
    "                                 L2_reg=[0.001, 0.0001])\n",
    "micro_configs = tuple(product(macro_configs, list(range(n_seeds))))\n",
    "\n",
    "### --- SELECT PARTICULAR CONFIG --- ###\n",
    "try:\n",
    "    i_job = int(os.environ['SLURM_ARRAY_TASK_ID']) - 1\n",
    "except KeyError:\n",
    "    i_job = 0\n",
    "params, i_seed = micro_configs[i_job]\n",
    "i_config = i_job//n_seeds\n",
    "\n",
    "new_random_seed_per_condition = True\n",
    "if new_random_seed_per_condition:\n",
    "    np.random.seed(i_job)\n",
    "else: #Match random seeds across conditions\n",
    "    np.random.seed(i_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fc9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10.0% complete \n",
      "Time Elapsed: 0.5s \n",
      "Test loss: 0.5926875651320297 \n",
      "\n",
      "Progress: 20.0% complete \n",
      "Time Elapsed: 1.2s \n",
      "Test loss: 0.22567720176092662 \n",
      "\n",
      "Progress: 30.0% complete \n",
      "Time Elapsed: 1.8s \n",
      "Test loss: 0.17166667707741476 \n",
      "\n",
      "Progress: 40.0% complete \n",
      "Time Elapsed: 2.5s \n",
      "Test loss: 0.013490525979990875 \n",
      "\n",
      "Progress: 50.0% complete \n",
      "Time Elapsed: 3.2s \n",
      "Test loss: 0.00549117957887174 \n",
      "\n",
      "Progress: 60.0% complete \n",
      "Time Elapsed: 3.9s \n",
      "Test loss: 0.04247337704855229 \n",
      "\n",
      "Progress: 70.0% complete \n",
      "Time Elapsed: 4.6s \n",
      "Test loss: 0.0041677683038541715 \n",
      "\n",
      "Progress: 80.0% complete \n",
      "Time Elapsed: 5.3s \n",
      "Test loss: 0.020775796418716158 \n",
      "\n",
      "Progress: 90.0% complete \n",
      "Time Elapsed: 6.0s \n",
      "Test loss: 0.003726477232464915 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "task = Flip_Flop_Task(3, 0.05, input_magnitudes=None)\n",
    "N_train = 20000\n",
    "N_test = 5000\n",
    "checkpoint_interval = 100\n",
    "sigma = 0\n",
    "\n",
    "data = task.gen_data(N_train, N_test)\n",
    "\n",
    "n_in = task.n_in\n",
    "n_hidden = 32\n",
    "n_out = task.n_out\n",
    "W_in  = np.random.normal(0, np.sqrt(1/(n_in)), (n_hidden, n_in))\n",
    "W_rec = np.random.normal(0, np.sqrt(1/n_hidden), (n_hidden, n_hidden))\n",
    "W_out = np.random.normal(0, np.sqrt(1/(n_hidden)), (n_out, n_hidden))\n",
    "\n",
    "b_rec = np.zeros(n_hidden)\n",
    "b_out = np.zeros(n_out)\n",
    "\n",
    "alpha = 1\n",
    "sigma = 0\n",
    "\n",
    "rnn = RNN(W_in, W_rec, W_out, b_rec, b_out,\n",
    "          activation=tanh,\n",
    "          alpha=alpha,\n",
    "          output=identity,\n",
    "          loss=mean_squared_error)\n",
    "\n",
    "learn_alg = RFLO(rnn, alpha=alpha, L2_reg=params['L2_reg'], L1_reg=0.0001)\n",
    "optimizer = SGD_Momentum(lr=params['lr'], mu=0.6)\n",
    "\n",
    "monitors = []\n",
    "\n",
    "sim = Simulation(rnn)\n",
    "sim.run(data, learn_alg=learn_alg, optimizer=optimizer,\n",
    "        sigma=sigma,\n",
    "        monitors=monitors,\n",
    "        verbose=True,\n",
    "        report_accuracy=False,\n",
    "        report_loss=True,\n",
    "        checkpoint_interval=checkpoint_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9596b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sim = Simulation(rnn)\n",
    "test_sim.run(data, mode='test', monitors=['rnn.loss_'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb05651",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- SAVE RESULTS -- ###\n",
    "result = {'sim': sim, 'i_seed': i_seed, 'task': task,\n",
    "          'config': params, 'i_config': i_config, 'i_job': i_job}\n",
    "try:\n",
    "    result['processed_data'] = processed_data\n",
    "except NameError:\n",
    "    pass\n",
    "    \n",
    "try:\n",
    "    save_dir = os.environ['SAVEDIR']\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    save_path = os.path.join(save_dir, 'result_'+str(i_job))\n",
    "\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(result, f)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('hell', 'potato', 'wants', 'you', 'dead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c24e3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pipeline_test.ipynb to script\n",
      "[NbConvertApp] Writing 3729 bytes to pipeline_test.py\n",
      "awk: 1: unexpected character '.'\n"
     ]
    }
   ],
   "source": [
    "###Truncate file above\n",
    "file_name = 'pipeline_test'\n",
    "job_name = 'scratch'\n",
    "get_ipython().run_cell_magic('javascript', '', 'IPython.notebook.save_notebook()')\n",
    "get_ipython().system('jupyter nbconvert --to script --no-prompt {}.ipynb'.format(file_name))\n",
    "get_ipython().system('awk \"/###Truncate/ {{exit}} {{print}}\" {}.py'.format(file_name))\n",
    "get_ipython().system('sed -i \"/###Truncate/Q\" {}.py'.format(file_name))\n",
    "get_ipython().system('mv {}.py ../cluster_main_scripts/{}.py'.format(file_name, job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ec640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending incremental file list\n",
      "vanilla-rtrl/.idea/\n",
      "vanilla-rtrl/.idea/workspace.xml\n",
      "vanilla-rtrl/cluster/\n",
      "vanilla-rtrl/cluster/submit_jobs.py\n",
      "vanilla-rtrl/cluster/__pycache__/\n",
      "vanilla-rtrl/cluster/__pycache__/submit_jobs.cpython-37.pyc\n",
      "vanilla-rtrl/cluster/__pycache__/submit_jobs.cpython-38.pyc\n",
      "\n",
      "sent 66,718 bytes  received 134 bytes  133,704.00 bytes/sec\n",
      "total size is 1,216,219  speedup is 18.19\n",
      "cp: cannot stat '/scratch/oem214/learning-dynamics/cluster_main_scripts/scratch.s': No such file or directory\n",
      "/bin/bash: sbatch: command not found\n"
     ]
    }
   ],
   "source": [
    "###Submit job to cluster\n",
    "n_jobs = len(micro_configs)\n",
    "write_job_file(job_name, py_file_name='{}.py'.format(job_name))\n",
    "submit_job('../job_scripts/scratch.s', n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bcbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/slurm/bin/sbatch: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!PATH=$PATH:/opt/slurm/bin/\n",
    "!/opt/slurm/bin/sbatch /scratch/oem214/learning-dynamics/job_scripts/scratch.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2adb329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/bin:/ext3/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/slurm/bin/\r\n"
     ]
    }
   ],
   "source": [
    "!PATH=$PATH:/opt/slurm/bin/ && echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66202a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sbatch /scratch/oem214/learning-dynamics/job_scripts/scratch.s\" > temp.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2358506d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: sbatch: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch /scratch/oem214/learning-dynamics/job_scripts/scratch.s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
